{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1158d329",
   "metadata": {},
   "source": [
    "THIS IS CODE FOR CALULATING SLOUCH BASED ON THE ANGLE BETWEEN YOUR LEFT SHOULDER RIGHT SHOULDER AND HIP AND VIS VERSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b7dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "def capture_reference_angles():\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "            # Calculate reference angles\n",
    "            left_angle = calculate_angle(left_shoulder, right_shoulder, right_hip)\n",
    "            right_angle = calculate_angle(right_shoulder, left_shoulder, left_hip)\n",
    "\n",
    "            # Display angles on the frame\n",
    "            cv2.putText(frame, f\"Left Angle: {int(left_angle)}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Right Angle: {int(right_angle)}\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('Capture Reference Posture', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                # Save the reference angles\n",
    "                cv2.imwrite('reference_posture.png', frame)\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                return left_angle, right_angle\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "reference_left_angle, reference_right_angle = capture_reference_angles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99159c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Reinitialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def check_posture(reference_left_angle, reference_right_angle, tolerance=10):\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "            # Calculate current angles\n",
    "            current_left_angle = calculate_angle(left_shoulder, right_shoulder, right_hip)\n",
    "            current_right_angle = calculate_angle(right_shoulder, left_shoulder, left_hip)\n",
    "\n",
    "            # Check if slouching\n",
    "            if (abs(current_left_angle - reference_left_angle) > tolerance or\n",
    "                abs(current_right_angle - reference_right_angle) > tolerance):\n",
    "                cv2.putText(frame, \"You are slouching!\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Good Posture\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display current angles on the frame\n",
    "            cv2.putText(frame, f\"Left Angle: {int(current_left_angle)}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Right Angle: {int(current_right_angle)}\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Posture Monitoring', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "check_posture(reference_left_angle, reference_right_angle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afe9b3",
   "metadata": {},
   "source": [
    "THE FOLLOWING CODE WILL BE TO CHECK IF THE Z COORDINATES OF YOUR LEFT AND RIGHT SHOULDER HAVE GONE BELOW THE LIMIT INDICATING THAT U HAVE SLOUCHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab860057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def capture_reference_heights():\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "\n",
    "            cv2.putText(frame, \"Press 's' to save reference position\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('Capture Reference Posture', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                # Save the reference y-coordinates\n",
    "                cv2.imwrite('reference_posture_y.png', frame)\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                return left_shoulder_y, right_shoulder_y\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Capture the reference shoulder heights using the y-coordinate\n",
    "reference_left_shoulder_y, reference_right_shoulder_y = capture_reference_heights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc1e1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Reinitialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def check_posture(reference_left_shoulder_y, reference_right_shoulder_y, tolerance=0.07):  # 7 cm tolerance\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            current_left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            current_right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "\n",
    "            # Check if slouching based on y-coordinate (vertical height)\n",
    "            if (current_left_shoulder_y > reference_left_shoulder_y + tolerance or\n",
    "                current_right_shoulder_y > reference_right_shoulder_y + tolerance):\n",
    "                cv2.putText(frame, \"You are slouching!\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Good Posture\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display current y-coordinates on the frame\n",
    "            cv2.putText(frame, f\"Left Shoulder Y: {round(current_left_shoulder_y, 4)}\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Right Shoulder Y: {round(current_right_shoulder_y, 4)}\", (10, 110), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Posture Monitoring', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Monitor the posture using the y-coordinate\n",
    "check_posture(reference_left_shoulder_y, reference_right_shoulder_y, tolerance=0.07)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd48964",
   "metadata": {},
   "source": [
    "This bath of code checks Y coordinate and adjusts it according to depth to make the predictions more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f36dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Coordinates: (0.6440290212631226, 0.6533220410346985, -0.1656002700328827, -0.4009275436401367)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def capture_reference_coordinates():\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Capture the y and z coordinates for the shoulders\n",
    "            left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "            left_shoulder_z = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "            right_shoulder_z = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "\n",
    "            cv2.putText(frame, \"Press 's' to save reference position\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('Capture Reference Posture', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                cv2.imwrite('reference_posture_coordinates.png', frame)\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                return (left_shoulder_y, right_shoulder_y, left_shoulder_z, right_shoulder_z)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Capture reference coordinates\n",
    "reference_coords = capture_reference_coordinates()\n",
    "print(f\"Reference Coordinates: {reference_coords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda43c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Reinitialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def adjust_y_based_on_z(current_y, current_z, ref_y, ref_z):\n",
    "    # Perspective-based adjustment using the given formula\n",
    "    adjusted_y = current_y * (-1.0 / current_z)\n",
    "    reference_adjusted_y = ref_y * (-1.0 / ref_z)\n",
    "    return adjusted_y, reference_adjusted_y\n",
    "\n",
    "def check_posture(reference_coords, tolerance=0.07):  # 7 cm tolerance\n",
    "    ref_left_shoulder_y, ref_right_shoulder_y, ref_left_shoulder_z, ref_right_shoulder_z = reference_coords\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            current_left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            current_right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "            current_left_shoulder_z = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "            current_right_shoulder_z = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "\n",
    "            # Adjust the y coordinates based on the current z coordinates using perspective projection formula\n",
    "            adjusted_left_shoulder_y, reference_adjusted_left_shoulder_y = adjust_y_based_on_z(\n",
    "                current_left_shoulder_y, current_left_shoulder_z, ref_left_shoulder_y, ref_left_shoulder_z)\n",
    "            adjusted_right_shoulder_y, reference_adjusted_right_shoulder_y = adjust_y_based_on_z(\n",
    "                current_right_shoulder_y, current_right_shoulder_z, ref_right_shoulder_y, ref_right_shoulder_z)\n",
    "\n",
    "            # Check if slouching based on adjusted y-coordinate\n",
    "            if (adjusted_left_shoulder_y > reference_adjusted_left_shoulder_y + tolerance or\n",
    "                adjusted_right_shoulder_y > reference_adjusted_right_shoulder_y + tolerance):\n",
    "                cv2.putText(frame, \"You are slouching!\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Good Posture\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display current and adjusted y-coordinates on the frame\n",
    "            cv2.putText(frame, f\"Adj Left Shoulder Y: {round(adjusted_left_shoulder_y, 4)}\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Adj Right Shoulder Y: {round(adjusted_right_shoulder_y, 4)}\", (10, 110), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Posture Monitoring', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Monitor the posture with adjusted y-coordinates based on z-coordinates\n",
    "check_posture(reference_coords, tolerance=0.07)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddb1af",
   "metadata": {},
   "source": [
    "THIS CODE IS UPDATED VERSION TAKING INTO CONSIDERATION THE Z- AXIS AND ITS WITH A DIFFRENT FORMULA WHICH WORKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def capture_reference_coordinates():\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Capture the y and z coordinates for the shoulders\n",
    "            left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "            left_shoulder_z = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "            right_shoulder_z = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "\n",
    "            cv2.putText(frame, \"Press 's' to save reference position\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('Capture Reference Posture', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                cv2.imwrite('reference_posture_coordinates.png', frame)\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                return (left_shoulder_y, right_shoulder_y, left_shoulder_z, right_shoulder_z)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Capture reference coordinates\n",
    "reference_coords = capture_reference_coordinates()\n",
    "print(f\"Reference Coordinates: {reference_coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71eb0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Reinitialize webcam and mediapipe\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def slight_adjustment_y_based_on_z(current_y, current_z, ref_y, ref_z):\n",
    "    # Apply a small adjustment to y based on the z coordinate\n",
    "    adjustment_factor = 0.1  # Adjust this factor for sensitivity\n",
    "    adjusted_y = current_y + adjustment_factor * (current_z - ref_z)\n",
    "    return adjusted_y\n",
    "\n",
    "def check_posture(reference_coords, tolerance=0.05):  # 5 cm tolerance\n",
    "    ref_left_shoulder_y, ref_right_shoulder_y, ref_left_shoulder_z, ref_right_shoulder_z = reference_coords\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            current_left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            current_right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "            current_left_shoulder_z = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "            current_right_shoulder_z = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "\n",
    "            # Slightly adjust the y coordinates based on the current z coordinates\n",
    "            adjusted_left_shoulder_y = slight_adjustment_y_based_on_z(\n",
    "                current_left_shoulder_y, current_left_shoulder_z, ref_left_shoulder_y, ref_left_shoulder_z)\n",
    "            adjusted_right_shoulder_y = slight_adjustment_y_based_on_z(\n",
    "                current_right_shoulder_y, current_right_shoulder_z, ref_right_shoulder_y, ref_right_shoulder_z)\n",
    "\n",
    "            # Check if slouching based on adjusted y-coordinate\n",
    "            if (adjusted_left_shoulder_y > ref_left_shoulder_y + tolerance or\n",
    "                adjusted_right_shoulder_y > ref_right_shoulder_y + tolerance):\n",
    "                cv2.putText(frame, \"You are slouching!\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Good Posture\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display current and adjusted y-coordinates on the frame\n",
    "            cv2.putText(frame, f\"Adj Left Shoulder Y: {round(adjusted_left_shoulder_y, 4)}\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Adj Right Shoulder Y: {round(adjusted_right_shoulder_y, 4)}\", (10, 110), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Posture Monitoring', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Monitor the posture with adjusted y-coordinates based on slight z-adjustment\n",
    "check_posture(reference_coords, tolerance=0.05)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
